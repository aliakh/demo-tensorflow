{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boston_housing_regression_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EIdT9iu_Z4Rb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Boston Housing Prices dataset: regression"
      ]
    },
    {
      "metadata": {
        "id": "1rRo8oNqZ-Rj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-zSaMIzIx8Ld",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are 14 attributes in each case of the dataset:\n",
        "1.\tCRIM - per capita crime rate by town\n",
        "2.\tZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "3.\tINDUS - proportion of non-retail business acres per town.\n",
        "4.\tCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
        "5.\tNOX - nitric oxides concentration (parts per 10 million)\n",
        "6.\tRM - average number of rooms per dwelling\n",
        "7.\tAGE - proportion of owner-occupied units built prior to 1940\n",
        "8.\tDIS - weighted distances to five Boston employment centres\n",
        "9.\tRAD - index of accessibility to radial highways\n",
        "10.\tTAX - full-value property-tax rate per 10,000 USD\n",
        "11.\tPTRATIO - pupil-teacher ratio by town\n",
        "12.\tB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "13.\tLSTAT - % lower status of the population\n",
        "14.\tMEDV - Median value of owner-occupied homes in 1000's USD\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "p9kxxgzvzlyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston_housing = keras.datasets.boston_housing\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n",
        "\n",
        "order = np.argsort(np.random.random(train_labels.shape))\n",
        "train_data = train_data[order]\n",
        "train_labels = train_labels[order]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyfEb6_dZCpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Examples and features \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ujqcgkipr65P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Training set: {}\".format(train_data.shape))  # 404 examples, 13 features\n",
        "print(\"Testing set:  {}\".format(test_data.shape))   # 102 examples, 13 features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tYsm8Gs03J4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"First training sample: {}\".format(train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYVyGhdyCpIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "column_names = [\n",
        "    'CRIM', \n",
        "    'ZN', \n",
        "    'INDUS', \n",
        "    'CHAS', \n",
        "    'NOX', \n",
        "    'RM', \n",
        "    'AGE', \n",
        "    'DIS', \n",
        "    'RAD',\n",
        "    'TAX', \n",
        "    'PTRATIO', \n",
        "    'B',\n",
        "    'LSTAT']\n",
        "\n",
        "df = pd.DataFrame(train_data, columns=column_names)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wb9S7Mia2lpf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Labels\n",
        "\n",
        "The labels are the house prices in thousands of dollars. "
      ]
    },
    {
      "metadata": {
        "id": "I8NwI2ND2t4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_labels[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRklxK5s388r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Normalize features\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ze5WQP8R1TYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean = train_data.mean(axis=0)\n",
        "std = train_data.std(axis=0)\n",
        "\n",
        "train_data = (train_data - mean) / std\n",
        "test_data = (test_data - mean) / std\n",
        "\n",
        "print(\"First training sample (normalized): {}\".format(train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmjdzxKzEu1-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "c26juK7ZG8j-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(train_data.shape[1],)),\n",
        "    keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.train.RMSPropOptimizer(0.001)\n",
        "\n",
        "  model.compile(\n",
        "      loss='mse',\n",
        "      optimizer=optimizer,\n",
        "      metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-qWCsh6DlyH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "metadata": {
        "id": "sD7qHCmNIOY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class print_dot_callback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self,epoch,logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "epochs = 500\n",
        "\n",
        "history = model.fit(\n",
        "    train_data, \n",
        "    train_labels, \n",
        "    epochs=epochs,\n",
        "    validation_split=0.2, \n",
        "    verbose=0,\n",
        "    callbacks=[print_dot_callback()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B6XriGbVPh2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history):\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [1000$]')\n",
        "  plt.plot(history.epoch, np.array(history.history['mean_absolute_error']), label='Train Loss')\n",
        "  plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']), label = 'Val loss')\n",
        "  plt.legend()\n",
        "  plt.ylim([0,5])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eMaOWIdcNSmu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Absolute Error: ${:7.2f}\".format(mae * 1000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdMZuhUgzMZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data, \n",
        "    train_labels, \n",
        "    epochs=epochs,\n",
        "    validation_split=0.2, \n",
        "    verbose=0,\n",
        "    callbacks=[early_stopping_callback, print_dot_callback()])\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jl_yNr5n1kms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Absolute Error: ${:7.2f}\".format(mae * 1000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ft603OzXuEZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Xe7RXH3N3CWU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_predictions = model.predict(test_data).flatten()\n",
        "\n",
        "print(test_predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}