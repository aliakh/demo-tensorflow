{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boston_housing_nn_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "eV16J6oUY-HN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Boston Housing Dataset: NN Regression"
      ]
    },
    {
      "metadata": {
        "id": "J2kqX6VZTHUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n"
      ]
    },
    {
      "metadata": {
        "id": "AGOM1TUiKNdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from IPython import display\n",
        "import math\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyCC_llTaWOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_file_url = \"https://storage.googleapis.com/mledu-datasets/california_housing_train.csv\"\n",
        "training_dataframe = pd.read_csv(training_file_url, sep=\",\")\n",
        "training_dataframe = training_dataframe.reindex(np.random.permutation(training_dataframe.index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I8E2qhyKNd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_features(dataframe):\n",
        "  selected_features = dataframe[\n",
        "    [\"latitude\",\n",
        "     \"longitude\",\n",
        "     \"housing_median_age\",\n",
        "     \"total_rooms\",\n",
        "     \"total_bedrooms\",\n",
        "     \"population\",\n",
        "     \"households\",\n",
        "     \"median_income\"]]\n",
        "  processed_features = selected_features.copy() \n",
        "  processed_features[\"rooms_per_person\"] = (dataframe[\"total_rooms\"] / dataframe[\"population\"])\n",
        "  return processed_features\n",
        "\n",
        "def preprocess_targets(dataframe):\n",
        "  processed_targets = pd.DataFrame()  \n",
        "  processed_targets[\"median_house_value\"] = (dataframe[\"median_house_value\"] / 1000.0)\n",
        "  return processed_targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78YZBhWKY9t_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TARGET_NAME = \"median_house_value\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pQzcj2B1T5dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_examples = preprocess_features(training_dataframe.head(12000))\n",
        "training_targets = preprocess_targets(training_dataframe.head(12000))\n",
        "\n",
        "validation_examples = preprocess_features(training_dataframe.tail(5000))\n",
        "validation_targets = preprocess_targets(training_dataframe.tail(5000))\n",
        "\n",
        "print(\"Training examples summary:\")\n",
        "display.display(training_examples.describe())\n",
        "print(\"Validation examples summary:\")\n",
        "display.display(validation_examples.describe())\n",
        "\n",
        "print(\"Training targets summary:\")\n",
        "display.display(training_targets.describe())\n",
        "print(\"Validation targets summary:\")\n",
        "display.display(validation_targets.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RWq0xecNKNeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building a Neural Network\n"
      ]
    },
    {
      "metadata": {
        "id": "ni0S6zHcTb04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_feature_columns(input_features):\n",
        "  return set([tf.feature_column.numeric_column(feature) for feature in input_features])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvCqgNdzpaFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
        "    features = {key:np.array(value) for key,value in dict(features).items()}                                             \n",
        " \n",
        "    ds = Dataset.from_tensor_slices((features,targets))\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "    \n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(10000)\n",
        "    \n",
        "    features2, targets2 = ds.make_one_shot_iterator().get_next()\n",
        "    return features2, targets2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U52Ychv9KNeH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_nn_regression_model(\n",
        "    learning_rate,\n",
        "    steps,\n",
        "    batch_size,\n",
        "    hidden_units,\n",
        "    training_examples,\n",
        "    training_targets,\n",
        "    validation_examples,\n",
        "    validation_targets):\n",
        "\n",
        "  periods = 10\n",
        "  steps_per_period = steps / periods\n",
        "  \n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "  optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
        "  \n",
        "  dnn_regressor = tf.estimator.DNNRegressor(\n",
        "      feature_columns=create_feature_columns(training_examples),\n",
        "      hidden_units=hidden_units,\n",
        "      optimizer=optimizer,\n",
        "  )\n",
        "  \n",
        "  training_input_fn = lambda: input_fn(\n",
        "      training_examples, \n",
        "      training_targets[TARGET_NAME], \n",
        "      batch_size=batch_size)\n",
        "  \n",
        "  predict_training_input_fn = lambda: input_fn(\n",
        "      training_examples, \n",
        "      training_targets[TARGET_NAME], \n",
        "      num_epochs=1, \n",
        "      shuffle=False)\n",
        "  \n",
        "  predict_validation_input_fn = lambda: input_fn(\n",
        "      validation_examples, \n",
        "      validation_targets[TARGET_NAME], \n",
        "      num_epochs=1, \n",
        "      shuffle=False)\n",
        "\n",
        "  print(\"Model training started.\")\n",
        "  print(\"RMSE (on training data):\")\n",
        "  \n",
        "  training_rmse_periods = []\n",
        "  validation_rmse_periods = []\n",
        "\n",
        "  for period in range (0, periods):\n",
        "    dnn_regressor.train(\n",
        "        input_fn=training_input_fn,\n",
        "        steps=steps_per_period\n",
        "    )\n",
        "\n",
        "    training_predictions = dnn_regressor.predict(input_fn=predict_training_input_fn)\n",
        "    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n",
        "    \n",
        "    validation_predictions = dnn_regressor.predict(input_fn=predict_validation_input_fn)\n",
        "    validation_predictions = np.array([item['predictions'][0] for item in validation_predictions])\n",
        "    \n",
        "    training_rmse = math.sqrt(metrics.mean_squared_error(training_predictions, training_targets))\n",
        "    validation_rmse = math.sqrt(metrics.mean_squared_error(validation_predictions, validation_targets))\n",
        "    \n",
        "    print(\"  period %02d : %0.2f\" % (period, training_rmse))\n",
        "\n",
        "    training_rmse_periods.append(training_rmse)\n",
        "    validation_rmse_periods.append(validation_rmse)\n",
        "\n",
        "  print(\"Model training finished.\")\n",
        "\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Periods\")\n",
        "  plt.title(\"Root Mean Squared Error vs. Periods\")\n",
        "  plt.tight_layout()\n",
        "  plt.plot(training_rmse_periods, label=\"training\")\n",
        "  plt.plot(validation_rmse_periods, label=\"validation\")\n",
        "  plt.legend()\n",
        "\n",
        "  print(\"Final RMSE (on training data):   %0.2f\" % training_rmse)\n",
        "  print(\"Final RMSE (on validation data): %0.2f\" % validation_rmse)\n",
        "\n",
        "  return dnn_regressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2QhdcCy-Y8QR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train a NN Model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IjkpSqmxqnSM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dnn_regressor = train_nn_regression_model(\n",
        "    learning_rate=0.001,\n",
        "    steps=2000,\n",
        "    batch_size=100,\n",
        "    hidden_units=[10, 10],\n",
        "    training_examples=training_examples,\n",
        "    training_targets=training_targets,\n",
        "    validation_examples=validation_examples,\n",
        "    validation_targets=validation_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6diezCSeH4Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate on Test Data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "vhb0CtdvrWZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_file_url = \"https://storage.googleapis.com/mledu-datasets/california_housing_test.csv\"\n",
        "test_dataframe = pd.read_csv(test_file_url, sep=\",\")\n",
        "\n",
        "test_examples = preprocess_features(test_dataframe)\n",
        "test_targets = preprocess_targets(test_dataframe)\n",
        "\n",
        "predict_test_input_fn = lambda: input_fn(\n",
        "    test_examples, \n",
        "    test_targets[TARGET_NAME], \n",
        "    num_epochs=1, \n",
        "    shuffle=False)\n",
        "\n",
        "test_predictions = dnn_regressor.predict(input_fn=predict_test_input_fn)\n",
        "test_predictions = np.array([item['predictions'][0] for item in test_predictions])\n",
        "\n",
        "test_rmse = math.sqrt(metrics.mean_squared_error(test_predictions, test_targets))\n",
        "\n",
        "print(\"Final RMSE (on test data): %0.2f\" % test_rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}