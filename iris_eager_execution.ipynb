{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_eager_execution.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JtEZ1pCPn--z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The Iris Dataset with Eager Execution\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "yNr7H-AIoLOR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup program"
      ]
    },
    {
      "metadata": {
        "id": "6qoYFqQ89aV3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Install the latest version of TensorFlow\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jBmKxLVy9Uhg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1J3AuPBT9gyR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configure imports and eager execution\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "g4Wzg69bnwK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Px6KAg0Jowz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import and parse the training dataset\n",
        "\n",
        "\n",
        "### Download the dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "J6c7uEU9rjRM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_file_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "training_file_path = tf.keras.utils.get_file(\n",
        "    fname=os.path.basename(training_file_url),\n",
        "    origin=training_file_url)\n",
        "\n",
        "print(\"Location of the training data file: {}\".format(training_file_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnX1-aLors4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Inspect the data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "FQvb_JYdrpPm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!head -n5 {training_file_path}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqPkQExM2Pwt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Parse the dataset\n"
      ]
    },
    {
      "metadata": {
        "id": "2y4OgiIz2CVb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def parse_csv_fn(line):\n",
        "  example_defaults = [[0.], [0.], [0.], [0.], [0]]\n",
        "  parsed_line = tf.decode_csv(line, example_defaults)\n",
        "  features = tf.reshape(parsed_line[:-1], shape=(4,))\n",
        "  target = tf.reshape(parsed_line[-1], shape=())\n",
        "  return features, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBGYOBS7zfdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create the training tf.data.Dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7YYQUa1Hz2pP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_dataset = tf.data.TextLineDataset(training_file_path).skip(1).map(parse_csv_fn).shuffle(buffer_size=1000).batch(32)\n",
        "\n",
        "features, target = iter(training_dataset).next()\n",
        "print(\"Features:\", features[0])\n",
        "print(\"Target:\", target[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LsaVrtNM3Tx5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Select the type of model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "W23DIMVPQEBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a model using Keras\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2fZ6oL2ig3ZK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(4,)),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(3)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vzq2E5J2QMtw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RaKp8aEjKX6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the loss and gradient function\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "x57HcKWhKkei",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_fn(model, features, y):\n",
        "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=model(features))\n",
        "\n",
        "def gradients_fn(model, features, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model, features, targets)\n",
        "  return tape.gradient(loss, model.variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOxFimtlKruu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create an optimizer\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8xxi2NNGKwG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Y2VSELvwAvW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training loop\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "AIgulGRUhpto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_mean_loss = []\n",
        "training_accuracy = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_mean_loss = tfe.metrics.Mean()\n",
        "  epoch_accuracy = tfe.metrics.Accuracy()\n",
        "\n",
        "  for x, y in training_dataset:\n",
        "    gradients = gradients_fn(model, x, y)\n",
        "\n",
        "    optimizer.apply_gradients(\n",
        "      zip(gradients, model.variables),\n",
        "      global_step=tf.train.get_or_create_global_step()\n",
        "    )\n",
        "\n",
        "    epoch_mean_loss(loss_fn(model, x, y))\n",
        "    epoch_accuracy(tf.argmax(model(x), axis=1, output_type=tf.int32), y)\n",
        "  \n",
        "  training_mean_loss.append(epoch_mean_loss.result())\n",
        "  training_accuracy.append(epoch_accuracy.result())\n",
        "  \n",
        "  if epoch % 10 == 0:\n",
        "    print(\"Epoch {:03d}: loss: {:.3f}, accuracy: {:.3%}\".format(\n",
        "      epoch,\n",
        "      epoch_mean_loss.result(),\n",
        "      epoch_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FQHVUnm_rjw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize the loss function over time"
      ]
    },
    {
      "metadata": {
        "id": "agjvNd2iUGFn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(training_mean_loss)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(training_accuracy)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zg8GoMZhLpGH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the model's effectiveness\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z-EvK7hGL0d8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup the test dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ps3_9dJ3Lodk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_file_url = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "test_file_path = tf.keras.utils.get_file(\n",
        "    fname=os.path.basename(test_file_url),\n",
        "    origin=test_file_url)\n",
        "\n",
        "test_dataset = tf.data.TextLineDataset(test_file_path).skip(1).map(parse_csv_fn).shuffle(1000).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HFuOKXJdMAdm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model on the test dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Tw03-MK1cYId",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_accuracy = tfe.metrics.Accuracy()\n",
        "\n",
        "for (x, y) in test_dataset:\n",
        "  prediction = tf.argmax(model(x), axis=1, output_type=tf.int32)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z2N2P8blHZue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use the trained model to make predictions\n"
      ]
    },
    {
      "metadata": {
        "id": "NkjcB7FzHZTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_names = ['Iris Setosa', 'Iris Versicolor', 'Iris Virginica']\n",
        "\n",
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [5.1, 3.3, 1.7, 0.5,],\n",
        "    [5.9, 3.0, 4.2, 1.5,],\n",
        "    [6.9, 3.1, 5.4, 2.1]\n",
        "])\n",
        "\n",
        "predictions = model(predict_dataset)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "    class_idx = tf.argmax(logits).numpy()\n",
        "    class_name = class_names[class_idx]\n",
        "    print(\"Example {} prediction: {}\".format(i, class_name))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}